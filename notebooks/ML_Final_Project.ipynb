{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#Explaination\n"
      ],
      "metadata": {
        "id": "AVeO_LVrFDjh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. **資料載入與整合:**\n",
        "\n",
        "  從六家飲料品牌（如一沐日、八曜、迷客夏等）匯入 CSV 檔，統一標記 brand 欄位後合併成單一 DataFrame。\n",
        "2. **資料清理與數值轉換:**\n",
        "\n",
        "  處理 like、comment、share 數值型態與空值填補，確保後續計算與建模穩定。\n",
        "自訂「熱度分數」以 like + 2×comment + 3×share 計算每則貼文的 popularity_score，將「留言」與「分享」權重提高。\n",
        "3. **情感分析特徵:**\n",
        "\n",
        "  使用中文 NLP 工具（SnowNLP）對貼文文字內容計算 sentiment_score（0～1），作為模型輸入之一。\n",
        "4. **標籤熱門貼文:**\n",
        "\n",
        "  依 popularity_score 排序，將分數前 25% 貼文標為「熱門」（is_popular=1），其餘為非熱門。\n",
        "5. **多模型訓練與比較:**\n",
        "  除了 Random Forest，亦訓練並比較 Logistic Regression、SVM、Gradient Boosting、AdaBoost，以及 XGBoost，並蒐集 Accuracy、Precision、Recall、F1-score 等指標。\n",
        "6. **模型效能視覺化:**\n",
        "\n",
        "  以熱圖（heatmap）呈現各演算法在上述指標上的表現，快速辨識最佳方案。\n",
        "7. **品牌情感趨勢分析:**\n",
        "\n",
        "  計算每日各品牌平均情感分數，繪製折線圖檢視品牌聲量與口碑變化趨勢。\n",
        "\n",
        "＃補充說明：\n",
        "1. 熱度分數的由來：\n",
        "\n",
        "    設計思路：我們希望整合「按讚」、「留言」、「分享」這三項互動行為，一方面反映不同的參與深度，另一方面簡化為可直接比大小的數值指標。\n",
        "\n",
        "    權重分配原則：\n",
        "    \n",
        "    1. 按讚(like)：屬於最輕度互動，只要滑動並點擊即可，因此設置權重為1。\n",
        "    2. 留言(comment)：需要花費使用者輸入文字的時間，代表中度參與，因此權重為2。\n",
        "    3. 分享(share)：按一次就能把貼文轉發給別人，，代表最高推廣意願，因此權重設為3。\n",
        "    \n",
        "  這樣的加權能夠凸顯「留言」與「分享」對貼文影響力的加乘效果，讓我們能更精準判斷哪些貼文在使用者眼中更具價值或更值得轉發。\n",
        "\n",
        "\n",
        "2. 為何挑選為何挑選那五個演算法？\n",
        "    1. **邏輯迴歸(Logistic Regression)**\n",
        "\n",
        "    性質：線性模型，易於借勢；作為基準模型，常用於二分類問題。\n",
        "\n",
        "    優點：參數少、運算快速，能快速檢是各特徵（like, comment, share, sentiment_score)與「熱門」之間的線性關係。\n",
        "    2. **支持向量機(SVM, RBF核)**\n",
        "\n",
        "    性質：非線性分類器，透過RBF核可以捕捉特徵空間中的複雜邊界。\n",
        "\n",
        "    優點：參數少、運算快速，能快速檢是各特徵（like, comment, share, sentiment_score)與「熱門」之間的線性關係。\n",
        "    3. **梯度提升樹(Gradient Boosting Classifier)**\n",
        "\n",
        "    性質：已逐步建樹提升方式累加弱分類器，強化預測能力。\n",
        "\n",
        "    優點：對中小型資料集往往能取得不錯的效果；能自動處理部分特徵非線性互動。\n",
        "\n",
        "    4. **AdaBoost(Adaptive Boosting)**\n",
        "\n",
        "    性質：透過反覆調整樣本權重，強化難分樣本\n",
        "\n",
        "    優點：演算法結構簡單，能在基分類器（如淺層決策樹）基礎上快速迭代；適合；適合嘗試是否樣本權重調整能提升效果。\n",
        "\n",
        "    5. **XGBoost(eXtreme Gradient Boosting)**\n",
        "\n",
        "    性質：基於梯度提升樹的進階版本，針對速度與正則化作了最佳化，並支援並行計算。\n",
        "\n",
        "    優點：在許多公開競賽中表現優異；技能處理缺失值，也能透過l1/l2正則化減少過你和風險；適合對複雜互動特徵進行細緻建模。\n",
        "\n",
        "從線性、非線性、到樹模型、涵蓋了不同「模型複雜度」與「學習機制」，透過這五種模型比較各自的準確度(Accuracy)、精確度(Precision)、召回率(Recall)、F1分數(f1-score)、找到最適合我們貼文特徵的演算法。\n",
        "\n",
        "3. 各個演算法的超參數有沒有調整？為什麼？\n",
        "\n",
        "  3.1 基本作法：先用預設參數作為基準\n",
        "\t  •\t在最初的探索階段，我們讓上面五種模型先以「預設超參數」進行訓練與交叉驗證，目的在於：\n",
        "\t  1.\t快速取得各模型大致效能，確認哪一類心模型最有潛力。\n",
        "\t  2.\t判斷是否需要進行更進一步的超參數調校（Hyperparameter Tuning）。\n",
        "    •\t例如：\n",
        "    •\tLogistic Regression 預設 C=1.0、penalty='l2'，\n",
        "  \t•\tXGBoost 預設 max_depth=6、learning_rate=0.3、n_estimators=100 等。\n",
        "\n",
        "  3.2 發現模型間差異後再做調校\n",
        "\t  •\t如果某個演算法在基準測試（如 5-fold CV）已經明顯落後，通常可先排除，將資源集中在幾個候選模型上。\n",
        "\t  •\t以 XGBoost 為例，我們在預設參數情況下，若其 F1 或 ROC-AUC 已接近專案需求（例如 > 0.85），則進一步使用 GridSearchCV 或 RandomizedSearchCV 優化：\n",
        "\t  •\t例如 max_depth（樹的深度） 值測試 [3, 5, 7]；\n",
        "\t  •\tlearning_rate（學習率） 測試 [0.01, 0.1, 0.2]；\n",
        "\t  •\tsubsample（抽樣比例） 測試 [0.6, 0.8, 1.0]；\n",
        "\t  •\tcolsample_bytree（每棵樹的特徵抽樣比例） 測試 [0.6, 0.8, 1.0]。\n",
        "\t  •\t而在****SVM 與 Logistic Regression，若輸出結果差距不大，也可考慮：\n",
        "  \t•\tSVM：使用 C [0.1, 1, 10]、gamma [‘scale’, 0.1, 1] 調參。\n",
        "  \t•\tLogistic：使用 C [0.01, 0.1, 1, 10]、penalty [‘l1’, ‘l2’]（搭配 solver=‘liblinear’）。\n",
        "\n",
        "  3.3 為何不一開始就大範圍調參？\n",
        "\t  •\t若資料量較大，完整調參（尤其是 XGBoost）需花費不少計算資源與時間。\n",
        "\t  •\t先以「預設參數」快速檢驗各演算法的「可行性」。\n",
        "\t  •\t盲目調整太多參數，反而可能導致在交叉驗證中過度擬合，在真實生產環境反而表現下降。"
      ],
      "metadata": {
        "id": "Kx7iK1qTFNwM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Setups"
      ],
      "metadata": {
        "id": "cwdi9yTe-EtP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "vKaZkVEMkVyG",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 291
        },
        "outputId": "02a2afb5-a9be-4d15-aaee-a7bdca2a2a1a"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "mount failed",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-d5df0069828e>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolab\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdrive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdrive\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/drive'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/google/colab/drive.py\u001b[0m in \u001b[0;36mmount\u001b[0;34m(mountpoint, force_remount, timeout_ms, readonly)\u001b[0m\n\u001b[1;32m     98\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mmount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmountpoint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mforce_remount\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout_ms\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m120000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreadonly\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m   \u001b[0;34m\"\"\"Mount your Google Drive at the specified mountpoint path.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 100\u001b[0;31m   return _mount(\n\u001b[0m\u001b[1;32m    101\u001b[0m       \u001b[0mmountpoint\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m       \u001b[0mforce_remount\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mforce_remount\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/google/colab/drive.py\u001b[0m in \u001b[0;36m_mount\u001b[0;34m(mountpoint, force_remount, timeout_ms, ephemeral, readonly)\u001b[0m\n\u001b[1;32m    277\u001b[0m             \u001b[0;34m'https://research.google.com/colaboratory/faq.html#drive-timeout'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    278\u001b[0m         )\n\u001b[0;32m--> 279\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'mount failed'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mextra_reason\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    280\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mcase\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    281\u001b[0m       \u001b[0;31m# Terminate the DriveFS binary before killing bash.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: mount failed"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install snownlp"
      ],
      "metadata": {
        "id": "3_yhLxG8tOLA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from snownlp import SnowNLP\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import classification_report, precision_recall_fscore_support, accuracy_score\n",
        "from xgboost import XGBClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.ensemble import GradientBoostingClassifier, AdaBoostClassifier"
      ],
      "metadata": {
        "id": "jqAhEtV_lz-C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "brand_files = {\n",
        "    \"Aniceholiday\" : \"/content/drive/MyDrive/Machine Learning/finish/一沐日_processed.csv\",\n",
        "    \"8yotea\" : \"/content/drive/MyDrive/Machine Learning/finish/八曜_processed.csv\",\n",
        "    \"Naptea\" : \"/content/drive/MyDrive/Machine Learning/finish/再睡五分鐘_processed.csv\",\n",
        "    \"Milksha\" : \"/content/drive/MyDrive/Machine Learning/finish/迷客夏_processed.csv\",\n",
        "    \"Macu\" : \"/content/drive/MyDrive/Machine Learning/finish/麻古_processed.csv\"\n",
        "}\n",
        "\n",
        "dfs = []\n",
        "for brand, file_path in brand_files.items():\n",
        "  df = pd.read_csv(file_path)\n",
        "  df['brand'] = brand\n",
        "  dfs.append(df)\n",
        "\n",
        "combined_data = pd.concat(dfs, ignore_index=True)"
      ],
      "metadata": {
        "id": "lMajaIfgkN6H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert like, comment, share to numeric and fill NaN with 0\n",
        "for col in ['like', 'comment', 'share']:\n",
        "    combined_data[col] = pd.to_numeric(combined_data[col], errors='coerce').fillna(0)"
      ],
      "metadata": {
        "id": "y3M6y25nrETU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Popularity Score Calculate"
      ],
      "metadata": {
        "id": "OSLBfnp7-Wli"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define popularity score formula\n",
        "combined_data['popularity_score'] = (\n",
        "    combined_data['like'] +\n",
        "    2 * combined_data['comment'] +\n",
        "    3 * combined_data['share']\n",
        ")"
      ],
      "metadata": {
        "id": "PFNQiwljrHAI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Display top 10 posts with their popularity score\n",
        "print(combined_data[['brand', 'content', 'like', 'comment', 'share', 'popularity_score']].head(10))"
      ],
      "metadata": {
        "id": "Szvb44K7rH9D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Sentimant Score using SnowNLP"
      ],
      "metadata": {
        "id": "6pCfriU8-c_W"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Ensure content is a string, then compute sentiment score\n",
        "combined_data['sentiment_score'] = combined_data['content'].astype(str).apply(lambda x: SnowNLP(x).sentiments)"
      ],
      "metadata": {
        "id": "WySPUbncs-X-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "combined_data"
      ],
      "metadata": {
        "id": "8aRJXGc2uGJ3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(10, 6))\n",
        "sns.scatterplot(data=combined_data, x='sentiment_score', y='popularity_score', hue='brand')\n",
        "plt.title('Sentiment Score vs Popularity Score by Brand')\n",
        "plt.xlabel('Sentiment Score (0 = Negative, 1 = Positive)')\n",
        "plt.ylabel('Popularity Score')\n",
        "plt.grid(True)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "zcg9Rme1z2jh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define threshold (75th percentile)\n",
        "threshold = combined_data['popularity_score'].quantile(0.75)\n",
        "\n",
        "# Create label column\n",
        "combined_data['is_popular'] = (combined_data['popularity_score'] >= threshold).astype(int)"
      ],
      "metadata": {
        "id": "pSaIjHM-zE2B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Feature and label selection\n",
        "features = combined_data[['like', 'comment', 'share', 'sentiment_score']]\n",
        "labels = combined_data['is_popular']\n",
        "\n",
        "# Split into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(features, labels, test_size=0.2, random_state=42)\n",
        "\n",
        "# Train a model\n",
        "model = RandomForestClassifier(random_state=42)\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Predict and evaluate\n",
        "y_pred = model.predict(X_test)\n",
        "print(classification_report(y_test, y_pred))"
      ],
      "metadata": {
        "id": "jgmBsp2Az1Gi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "importances = model.feature_importances_\n",
        "for feature, importance in zip(features.columns, importances):\n",
        "    print(f\"{feature}: {importance:.3f}\")"
      ],
      "metadata": {
        "id": "P7SUi-iV0Dw_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Different Models"
      ],
      "metadata": {
        "id": "6tEXNOGZ_tSl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 1) Prepare features & labels\n",
        "features = combined_data[['like', 'comment', 'share', 'sentiment_score']]\n",
        "labels   = combined_data['is_popular']\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    features, labels, test_size=0.2, random_state=42\n",
        ")\n",
        "\n",
        "# 2) Define multiple models\n",
        "models = {\n",
        "    \"Logistic Regression\": LogisticRegression(max_iter=1000, random_state=42),\n",
        "    \"SVM\": SVC(kernel='rbf', probability=True, random_state=42),\n",
        "    \"Gradient Boosting\": GradientBoostingClassifier(random_state=42),\n",
        "    \"AdaBoost\": AdaBoostClassifier(random_state=42),\n",
        "    \"XGBoost\": XGBClassifier(use_label_encoder=False, eval_metric='logloss', random_state=42),\n",
        "}\n",
        "\n",
        "# 3) Train, predict, and collect metrics\n",
        "results = []\n",
        "for name, model in models.items():\n",
        "    model.fit(X_train, y_train)\n",
        "    y_pred = model.predict(X_test)\n",
        "    acc = accuracy_score(y_test, y_pred)\n",
        "    precision, recall, f1, _ = precision_recall_fscore_support(y_test, y_pred, average='binary')\n",
        "    results.append({\n",
        "        \"Model\": name,\n",
        "        \"Accuracy\": acc,\n",
        "        \"Precision\": precision,\n",
        "        \"Recall\": recall,\n",
        "        \"F1-Score\": f1\n",
        "    })\n",
        "\n",
        "results_df = pd.DataFrame(results).set_index(\"Model\")\n",
        "\n",
        "# 4) Visualize the comparison\n",
        "plt.figure(figsize=(8, 5))\n",
        "sns.heatmap(results_df, annot=True, fmt=\".2f\", cmap=\"Blues\")\n",
        "plt.title(\"Model Performance Comparison\")\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# 5) Print the DataFrame\n",
        "results_df"
      ],
      "metadata": {
        "id": "YB4L6ivD_bkC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import StratifiedKFold, cross_val_score\n",
        "from xgboost import XGBClassifier\n",
        "\n",
        "# 1) Prepare your features & labels\n",
        "X = combined_data[['like', 'comment', 'share', 'sentiment_score']]\n",
        "y = combined_data['is_popular']\n",
        "\n",
        "# 2) Instantiate your model\n",
        "model = XGBClassifier(\n",
        "    use_label_encoder=False,\n",
        "    eval_metric='logloss',\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "# 3) Set up Stratified K-Fold\n",
        "kf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
        "\n",
        "# 4) Perform cross-validation\n",
        "scores = cross_val_score(\n",
        "    model,        # estimator\n",
        "    X,            # features\n",
        "    y,            # labels\n",
        "    cv=kf,        # cross-validator\n",
        "    scoring='f1'  # or 'accuracy', 'precision', 'recall', 'roc_auc'\n",
        ")\n",
        "\n",
        "# 5) Report results\n",
        "print(f\"5-Fold F1 scores: {scores}\")\n",
        "print(f\"Mean F1: {scores.mean():.3f}  ±  {scores.std():.3f}\")"
      ],
      "metadata": {
        "id": "b9Zf7ZizGqqh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import cross_val_score\n",
        "from xgboost import XGBClassifier\n",
        "\n",
        "# 1) Re-instantiate your model (unfitted)\n",
        "model = XGBClassifier(use_label_encoder=False, eval_metric='logloss', random_state=42)\n",
        "\n",
        "# 2) Define metrics\n",
        "metrics = ['accuracy', 'precision', 'recall', 'f1', 'roc_auc']\n",
        "\n",
        "# 3) Run cross-validation for each metric\n",
        "scores = {}\n",
        "for metric in metrics:\n",
        "    scores[metric] = cross_val_score(\n",
        "        model,\n",
        "        X,\n",
        "        y,\n",
        "        cv=kf,\n",
        "        scoring=metric\n",
        "    )\n",
        "\n",
        "# 4) Print results\n",
        "for metric in metrics:\n",
        "    print(f\"{metric.upper()} per fold: {scores[metric]}\")"
      ],
      "metadata": {
        "id": "-ik9gr7xR3tO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Q4gHkjYMZer3"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}